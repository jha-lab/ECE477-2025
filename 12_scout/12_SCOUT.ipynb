{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g3ivv9pWqOKZ"},"source":["#Put your Google Colab link here:\n","*your link here*"]},{"cell_type":"markdown","source":["## Checklist\n","Before beginning, please make sure you are connected to a GPU runtime (go to Runtime > Change runtime type > select T4 GPU)"],"metadata":{"id":"tTPelkw9SkZt"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"tHm-jEXlj6pz"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!unzip \"/content/drive/Shareddrives/ECE477 datasets/Assignment12/scout.zip\" -d \"./\""],"metadata":{"id":"TIqnGEWxTBya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y transformers\n","!pip install --no-cache-dir -e /content/scout/transformers"],"metadata":{"id":"wLClv2oKkGUv","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#verify installation\n","import sys\n","sys.path.append('/content/scout/transformers/src/')\n","import transformers\n","print(transformers.__file__)\n","#Expected output: /content/scout/transformers/src/transformers/__init__.py\n","#Incase of error disconnect and delete runtime (see Runtime > Disconnect and delete runtime)"],"metadata":{"id":"DMWdMRaPp9-L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For this assignment we are going to run a randomized trial using SCouT. Let's start by understanding the problem scenario first.\n","\n","# Problem Description\n","The Childhood Asthma Management Program (CAMP) (https://pmc.ncbi.nlm.nih.gov/articles/PMC3546823/) was a clinical trial carried out in children with asthma. The trial was designed to determine the long-term effects of 3 treatments (budesonide, nedocromil, or placebo) on pulmonary function as measured by normalized FEV1 over a 5-6.5 year period. The design of CAMP was a multicenter, masked, placebo-controlled, randomized trial. A total of 1,041 children (311 in the budesonide group, 312 in the nedocromil group and 418 in the placebo group) aged 5-12 years were enrolled between December of 1993 and September of 1995. The primary outcome of the trial was lung function as measured by the Forced Expiratory Volume at 1 second (FEV1).\n","\n","The trialâ€™s placebo arm contains anonymized longitudinal data of 275 patients with over 20 spirometry measurements per patient. For each donor,\n","we use several 16 different repiratory physiological signals. We are particularly interested in the Pre-Bronchodilator Forced Expiratory Volume to Forced Vital Capacity (PreFF). PreFF ratio is a vital metric of\n","lung capacity in asthma patients that measures volume of air that an individual can exhale during a forced breath\n","prior to the usage of a bronchodilator. Here, we model the control arm of the RCT and predict the PreFF of a\n","target patient using the other placebos as donors. This means that we are going to answer the counterfactual \"what would have happened to the target unit had there been no intervention\".\n","\n","Let's begin by building our dataset first:"],"metadata":{"id":"DuST7t91kCKH"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","import os\n","import glob\n","from datetime import datetime\n","\n","\n","df = pd.read_csv('/content/scout/datasets/asthma/camp_teach.csv')\n","#keep control (C) and ID 79 bud (A) for placebo arm\n","df = df[df['TG'] == 'C']\n","\n","li_final = []\n","for idx in df.id.unique():\n","    df_idx = df[df['id'] == idx]\n","    dic_list = []\n","    for date in df.visitc.unique():\n","        if date not in df_idx.visitc.unique():\n","            dic = {'id': idx, 'visitc': date}\n","            dic_list.append(dic)\n","\n","    rows = pd.DataFrame.from_dict(dic_list)\n","    df_idx_ = pd.concat([df_idx, rows], ignore_index=True, sort=True)\n","    li_final.append(df_idx_)\n","\n","df = pd.concat(li_final)\n","\n","#extract continuous and discrete features\n","continuous_features = ['PREFF','age_rz', 'hemog', 'PREFEV', 'PREFVC',  'PREPF', 'POSFEV', 'POSFVC',\n","                      'POSFF', 'POSPF', 'PREFEVPP', 'PREFVCPP', 'POSFEVPP', 'POSFVCPP', 'wbc', 'agehome']\n","units = ['id']\n","time = ['visitc'] #choose months\n","df = df[units + time + continuous_features] #state, time, continuous features\n","\n","\n","scaler = MinMaxScaler()\n","scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n","features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n","df.loc[:, df.columns.isin(continuous_features)] = features\n","\n","n_units = len(df.id.unique()) #number of units\n","n_time = len(df.visitc.unique()) #number of time steps\n","n_units, n_time\n","\n","print('Number of placebo units:', n_units)\n","print('Number of visits:', n_time)"],"metadata":{"id":"qORO6x_QxOk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#let's visualise the data\n","df.head()"],"metadata":{"id":"3RcBu9AwqyaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above data has missing values as denoted by the 'NaN' values. This is a very real-world medical occurence where patients may or may not get certain tests done after visits or the data may simply be missing /corrupted.\n","\n","The SCouT framework deals with missing values by applying a low-rank transformation (https://en.wikipedia.org/wiki/Low-rank_approximation) to the spatiotemporal matrix. In order to do that let's replace missing values with zero and create a mask that points to the missing values in the data."],"metadata":{"id":"C1ApJpNOv_E6"}},{"cell_type":"code","source":["# [state, year, feature value]\n","df = df.sort_values(by=['id', 'visitc'])\n","mask_df = np.array(df.isna())\n","df = df.fillna(0)\n","\n","arr = df.values.reshape(n_units, n_time, df.shape[1])[:, :, 2:] #remove id and visits\n","mask = mask_df.reshape(n_units, n_time, df.shape[1])[:, :, 2:]  #remove id and months\n","\n","print('Data shape:', arr.shape)\n","print('Mask shape:', mask.shape)\n","\n","np.save('/content/scout/datasets/asthma/data.npy', arr)\n","np.save('/content/scout/datasets/asthma/mask.npy', mask)"],"metadata":{"id":"3B99igztsJSM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SCouT Library Demonstration\n","\n","For this assignment the SCouT library along with all its trainer and dataloading functionalities have been provided to you.\n","\n","Lets do a simple demonstration. First, we will explore pretraining SCOuT on a sample target id and pre-intervention length. Then we will finetune SCouT on the target followed by predicting the counterfactual."],"metadata":{"id":"9G35-rr7Mb4I"}},{"cell_type":"code","source":["\n","from matplotlib import pyplot as plt\n","import sys\n","sys.path.append('/content/scout/')\n","import torch\n","from dsc.dsc_model import DSCModel\n","from models.bert2bert import Bert2BertSynCtrl\n","from transformers import BertConfig\n","import random\n","\n","random_seed = 42\n","device = torch.device('cuda:0' if torch.cuda.is_available else \"cpu\")\n","op_path = '/content/scout/logs/'\n","datapath = '/content/scout/datasets/asthma/'\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","config = {\n","    'feature_dim': 16,\n","    'cont_dim' : 16,\n","    'discrete_dim': 0,\n","    'hidden_size' : 128,\n","    'n_layers' : 4,\n","    'n_heads' : 1,\n","    'K' : 274,\n","    'pre_int_len': 2,\n","    'post_int_len': 2,\n","    'seq_range' : 275,\n","    'time_range' : 20,\n","    'batch_size' : 16,\n","    'lr': '1e-4',\n","    'weight_decay' : '1e-4',\n","    'warmup_steps' : 10000\n","}"],"metadata":{"id":"PrtsxS8nz4y0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#lets initialize the model with the default params\n","config_model = BertConfig(hidden_size = config['hidden_size'],\n","                        num_hidden_layers = config['n_layers'],\n","                        num_attention_heads = config['n_heads'],\n","                        intermediate_size = 4*config['hidden_size'],\n","                        vocab_size = 0,\n","                        max_position_embeddings = 0,\n","                        output_hidden_states = True,\n","                        )\n","config_model.add_syn_ctrl_config(K=config['K'],\n","                                pre_int_len=config['pre_int_len'],\n","                                post_int_len=config['post_int_len'],\n","                                feature_dim=config['feature_dim'],\n","                                time_range=config['time_range'],\n","                                seq_range=config['seq_range'],\n","                                cont_dim=config['cont_dim'],\n","                                discrete_dim=config['discrete_dim'],\n","                                classes = None)\n","model = Bert2BertSynCtrl(config_model, random_seed)\n","model = model.to(device)\n"],"metadata":{"id":"dPQ3GDiQD5bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","DSCModel is the main SCouT class that wraps the dataloading, training and model inference capabilties under one wrapper.\n","The assignment tasks will involve modifying the instantiation of the DSCModel class.\n","The main parameters that will be needed to be tweaked is:\n","target_id: Denotes the index of the target index (starting from 0)\n","'''\n","target_id = 0\n","interv_time = 13\n","dscmodel = DSCModel(model = model,\n","                    config = config,\n","                    op_dir = op_path,\n","                    target_id = 0,\n","                    interv_time = interv_time,\n","                    random_seed = random_seed,\n","                    datapath = datapath,\n","                    device = device,\n","                    topk = None,\n","                    weights = None,\n","                    lowrank = True,\n","                    classes=None)"],"metadata":{"id":"pwAb47HaiYud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lets pretrain SCouT first\n","dscmodel.pretrain(num_iters=3e3)"],"metadata":{"id":"2uS4UjNYQ9tU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lets finetune SCOuT on the target pre-intervention period\n","dscmodel.finetune(num_iters=3e3)"],"metadata":{"id":"AshwJidRd_3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","We calculate the prediction error by\n","'''\n","mask = np.load(datapath+'mask.npy')\n","data = np.load(datapath+'data.npy')\n","#model prediction\n","pred = dscmodel.predict()[interv_time:]\n","ctrl  = data[target_id,interv_time:,0]\n","dsc_rmse = np.sqrt(np.mean(((pred -ctrl)*(1-mask[target_id,interv_time:,0]))**2))\n","print(dsc_rmse)"],"metadata":{"id":"mvDar-gLkZwn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task: Analysing the Effect of Pre-Training\n","\n","SCouT relies on unsupervised pre-training to learn effective transformer embeddings. You have to analyse the effect of pre-training by training SCOuT with and without the pre-training step. This ablation will be performed over three different target units. Basic starter code has been provided to you."],"metadata":{"id":"YjShLlrw3mhi"}},{"cell_type":"markdown","source":["## 1. Traing with / without the pre-training step (10 pts)\n","You should learn how to use scout library in the previous code cells."],"metadata":{"id":"G754CPIDHog8"}},{"cell_type":"code","source":["#Fill in the code (10 points)\n","data = np.load(datapath+'data.npy')\n","mask = np.load(datapath+'mask.npy')\n","\n","errors_with_pretraining = []\n","errors_without_pretraining = []\n","interv_time = 10\n","for ablation_id in range(3):\n","  # With pretraining\n","  \"\"\" TO DO \"\"\"\n","\n","  errors_with_pretraining.append(dsc_rmse_with_pretraining)\n","  print(f\"ID {ablation_id}: RMSE with pretraining = {dsc_rmse_with_pretraining}\")\n","\n","  # Without pretraining\n","  \"\"\" TO DO \"\"\"\n","\n","  errors_without_pretraining.append(dsc_rmse_without_pretraining)\n","  print(f\"ID {ablation_id}: RMSE without pretraining = {dsc_rmse_without_pretraining}\")\n"],"metadata":{"id":"Z0ro3uys3lzP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Plot errors (6 pts)"],"metadata":{"id":"_xqJcv9PH1GV"}},{"cell_type":"code","source":["# plot and compare the errors along with error bars (6 points)\n","# Please average the error over three target ids and plot the std deviation error bars\n","import matplotlib.pyplot as plt\n","\n","# compute std and mean\n","\"\"\" TO DO \"\"\"\n","std_with_pretraining =\n","std_without_pretraining =\n","print(f\"Std with pretraining = {std_with_pretraining}\")\n","print(f\"Std without pretraining = {std_without_pretraining}\")\n","\n","mean_with_pretraining =\n","mean_without_pretraining =\n","print(f\"Mean with pretraining = {mean_with_pretraining}\")\n","print(f\"Mean without pretraining = {mean_without_pretraining}\")\n","\n","# plot the std error bars, with / without pretraining\n","# Set labels for better visualization\n","\"\"\" TO DO \"\"\"\n"],"metadata":{"id":"rJFL_iMY68Xc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Give a brief explanation of what trend you observe and why that might be happening? (4 pts).\n","\n","Your answer here"],"metadata":{"id":"MYpWC15oMqfb"}}]}